 # @package _global_
defaults:
  - override /trainers: trainer_maml
  - override /models: mlp_modulation
  - override /datasets: cifar10
  - override /sdes: heat_subvp
  - override /samplers: pc_sampler
  - override /predictors: euler
  - override /correctors: langevin
  - override /metrics: metrics_cifar10


trainers:
  mode: "eval"
  model_name: "local"
  training_config:
    inner_steps: 3
    use_meta_sgd: True
    ema_rate: 0.9999
    save_dir: ${oc.env:LOGS_ROOT}/inr_cifar10
  trainer_logging:
    use_wandb: True

  evaluation_config:
    seed: 43 # random seed for reproducibility
    eval_dir: ${oc.env:LOGS_ROOT}/inr_cifar10
    num_samples: 500 # number of samples to be generated for evaluation

sdes:
  sde_config:
    beta_max: 5.0
    const: 0.02
    factor: 1.0
    probability_flow: True
    x_norm: 32
    energy_norm: 1

correctors:
  snr: 0.17

samplers:
  sampler_config:
    N: 400
    k: 1
    denoise: True

models:
  model_config:
    layer_sizes:
      - 256
      - 256
      - 256
      - 256
      - 256
      - 256
      - 256
      - 256
      - 256
      - 256
      - 256
      - 256
      - 256
      - 256
      - 256
      - ${datasets.test.data_config.output_size}
    y_input: True
datasets:
  test:
    _target_: functional_diffusion_processes.datasets.cifar10_dataset.CIFAR10Dataset
    data_config:
      image_height_size: 32
      image_width_size: 32
      batch_size: 512
